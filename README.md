# V-LiDAR: A system for generating virtual LiDAR data

## Installation:

This library depends on  [Comma](https://github.com/acfr/comma) and [Snark](https://github.com/acfr/snark) (by ACFR).

We include Arbaro for tree generation, presented [here](https://www2.cs.duke.edu/courses/cps124/spring08/assign/07_papers/p119-weber.pdf) and licensed under GNU General Public License version 2.0 (GPLv2).

Included in the directory is an install.sh script which should install all dependencies correctly on a clean install of Ubuntu.  As of September 2019, this works on Ubuntu 18.04 running as a Windows Subsystem for Linux (WSL) 2, but the ACFR libraries are quite old, so may be subject to breaking changes.

If you are running WSL, make sure to set up X display forwarding or graphics won't work.

Once everything is installed, you need to:
  
  1. run `source config.sh` to get access to the various tools, 
  2. If generating trees, you need to copy arbaro_cmd.jar into your working directory (for now).

## Utilities:

## Input parameters

For the generation scripts, there are three main parameters you need to control:


### Tree
First of all, it needs to be fed a tree definition (XML) generated in Arbaro.  This is currently entered using the functions in the "trees" directory, which simply echo the XML file.

To create a custom tree definition, you can use `arbaro.xml` to tweak the parameters and see the resulting tree.


### Sensor
It also needs a sensor definition. The way this is defined is by a binary file
which lists a set of lines generated by the LiDAR sensor at any one point in the
trajectory of the sensor. For instance, the Zeb1 sensor scans across 270
degrees at a 0.625 degree interval, with a maximum distance (outside) of 15m.
The "low-quality" fake sensor has a 1 degree interval and a maximum distance of 8m.
The line length in this sensor definition is important, as is the orientation
of the sensor plane.

To make a new sensor definition, the easiest way is to copy the scripts currently generating HD and LD sensors, and adjust it to suit your sensor.


### Trajectory
The last thing that's needed is a sensor trajectory - how the sensor will move
around the generated stand of trees to generate the point cloud.
For instance, the Zeb1 sensor is bounced around in a circle around the tree.
The LiDAR on Shrimp spins continuously while travelling in straight lines.
These trajectories need to be defined in a specific global reference frame,
and rotation must be defined by quaternion. The reference frame used currently
derives from the definition provided by GeoSLAM in the Zebedee output files.

The "zeb" trajectory in the "trajectories" folder uses sensor localisation data to generate a trajectory, but the "drone" and "shrimp" trajectories are procedurally generated and easy to copy and customise.


## Utilities

For all of the below, use the "-h" flag to get a detailed description of inputs.

* `generate-stand` creates a set of highly virtual trees (saved in temp files at `~/gpc_temp`) and builds a stand using your choice of forest vs orchard and spacing parameters.
* `sample-sensor` takes in a high-density point cloud like those generated by `generate-stand`, and runs a virtual LiDAR through it to generate a simulated cloud.
* `generate-pointcloud` does the whole process of generating a stand of trees and simulating a LiDAR through it.

* `csv-from-obj` takes in an OBJ file (with fairly simple specifications, the entire OBJ spec is not yet supported) and outputs a point cloud by sampling the mesh.
* `view-obj` takes in an OBJ file and visualises it in 3D so you can see it.
